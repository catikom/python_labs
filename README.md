<!-- # PYTHON LABS
## LAB_01
### –ó–∞–¥–∞–Ω–∏–µ 1

```py
name = str(input('–ò–º—è: '))
age = int(input('–í–æ–∑—Ä–∞—Å—Ç: '))
print(f'–ü—Ä–∏–≤–µ—Ç, {name}! –ß–µ—Ä–µ–∑ –≥–æ–¥ —Ç–µ–±–µ –±—É–¥–µ—Ç {age+1}.')
```

![–ó–∞–¥–∞–Ω–∏–µ 1](/images/lab01/01_greeting.py.png)

### –ó–∞–¥–∞–Ω–∏–µ 2

```py
a = float(str(input('a: ')).replace(',', '.'))
b = float(str(input('b: ')).replace(',', '.'))
print(f'sum={format(a+b, '.2f')}; avg={format((a+b)/2, '.2f')}')
```

![–ó–∞–¥–∞–Ω–∏–µ 2](/images/lab01/02_sum_avg.py.png)

### –ó–∞–¥–∞–Ω–∏–µ 3

```py
price = int(input())
discount = int(input())
vat = int(input())
base = price * (1 - discount / 100)
vat_amount = base * (vat / 100)
total = base + vat_amount
print(f"–ë–∞–∑–∞ –ø–æ—Å–ª–µ —Å–∫–∏–¥–∫–∏: {format(base, '.2f')} —Ä—É–±")
print(f"–ù–î–°:               {format(vat_amount, '.2f')} —Ä—É–±")
print(f"–ò—Ç–æ–≥–æ –∫ –æ–ø–ª–∞—Ç–µ:    {format(total, '.2f')} —Ä—É–±")
```

![–ó–∞–¥–∞–Ω–∏–µ 3](/images/lab01/03_discount_vat.py.png)

### –ó–∞–¥–∞–Ω–∏–µ 4

```py
min = int(input('–ú–∏–Ω—É—Ç—ã: '))
print(f'{(min // 60):02d}:{(min % 60):02d}')
```

![–ó–∞–¥–∞–Ω–∏–µ 4](images/lab01/04_minutes_to_hhmm.py.png)

### –ó–∞–¥–∞–Ω–∏–µ 5

```py
fio = str(input('–§–ò–û: '))
for i in range(len(fio)):
    fio = fio.replace(" ", "")
init = ''
for i in fio:
    if i.upper() == i:
        init += i
print(f'–ò–Ω–∏—Ü–∏–∞–ª—ã: {init}.')
print('–î–ª–∏–Ω–∞ (—Å–∏–º–≤–æ–ª–æ–≤):', len(fio) + 2)
```

![–ó–∞–¥–∞–Ω–∏–µ 5](/images/lab01/05_initials_and_len.py.png)



## LAB_02

### –ó–∞–¥–∞–Ω–∏–µ 1 (min_max)

```py
def min_max(nums: list[float | int]) -> tuple[float | int, float | int]:

    if nums == []:
        raise ValueError('–°–ø–∏—Å–æ–∫ –ø—É—Å—Ç–æ–π') 
    '''–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç ValueError, –µ—Å–ª–∏ —Å–ø–∏—Å–æ–∫ –ø—É—Å—Ç–æ–π'''
    
    mini = nums[0]
    for next in nums:
        if next < mini:
            mini = next 
    maxi = nums[0]
    for next in nums:
        if next > mini:
            maxi = next 

    return mini, maxi 
    '''–í –¥—Ä—É–≥–æ–º —Å–ª—É—á–∞–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –º–∏–Ω–∏–º—É–º –∏ –º–∞–∫—Å–∏–º—É–º –∏–∑ —Å–ø–∏—Å–∫–∞'''
```

![–ó–∞–¥–∞–Ω–∏–µ 1(min_max)](/images/lab02/01_arrays_min_max.png)

### –ó–∞–¥–∞–Ω–∏–µ 1 (unique_sorted)

```py
def unique_sorted(nums: list[float | int]) -> list[float | int]:

    nums = list(set(nums))
    n = len(nums)
    for i in range(n):
        for j in range(0, n - i - 1):
            if nums[j] > nums[j + 1]:
                nums[j], nums[j + 1] = nums[j + 1], nums[j]

                '''
                –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø—É–∑—ã—Ä—å–∫–æ–º:
                –ö–∞–∂–¥—ã–π –ø—Ä–æ—Ö–æ–¥ –±–û–ª—å—à–µ–≥–æ —Ü–∏–∫–ª–∞ "–≤—Å–ø–ª—ã–≤–∞–µ—Ç" —Å–∞–º—ã–π –±–æ–ª—å—à–æ–π —ç–ª–µ–º–µ–Ω—Ç –∏–∑
                –Ω–µ–æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–π —á–∞—Å—Ç–∏. –° –∫–∞–∂–¥—ã–º –ø—Ä–æ—Ö–æ–¥–æ–º —Å–æ–∫—Ä–∞—â–∞–µ–º –¥–∏–∞–ø–∞–∑–æ–Ω, —Ç.–∫.
                –ø–æ—Å–ª–µ–¥–Ω–∏–µ i —ç–ª–µ–º–µ–Ω—Ç–æ–≤ —É–∂–µ –Ω–∞ —Å–≤–æ–∏—Ö –º–µ—Å—Ç–∞—Ö. –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ —á–∏—Å–ª–∞
                '''
                
    return nums
```

![–ó–∞–¥–∞–Ω–∏–µ 1(unique_sorted)](/images/lab02/01_arrays_unique_sorted.png)

### –ó–∞–¥–∞–Ω–∏–µ 1 (flatten)

```py
def flatten(mat: list[list | tuple]) -> list:
    
    new_mat = []
    for elements in mat:
            if isinstance(elements, tuple | list):
                '''–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —Å–ø–∏—Å–æ–∫/–∫–æ—Ä—Ç–µ–∂ –ª–∏ —ç–ª–µ–º–µ–Ω—Ç'''

                for element in elements:
                    new_mat.append(element)
                '''
                –ï—Å–ª–∏ –≤—Å–µ —ç–ª–µ–º–µ–Ω—Ç—ã —É–¥–æ–≤–ª–µ—Ç–≤–æ—Ä—è—é—Ç —É—Å–ª–æ–≤–∏—é, —Ç–æ –ø—Ä–æ—Ö–æ–¥–∏–º—Å—è –ø–æ
                —ç–ª–µ–º–µ–Ω—Ç–∞–º –≤–Ω—É—Ç—Ä–∏ –∫–∞–∂–¥–æ–≥–æ –∏–∑ –Ω–∏—Ö –∏ –¥–æ–±–∞–≤–ª—è–µ–º –≤ "—Å–ø–ª—é—â–µ–Ω–Ω—É—é" –º–∞—Ç—Ä–∏—Ü—É
                '''
                
            else:
                raise TypeError('–≠–ª–µ–º–µ–Ω—Ç –Ω–µ —Ç–æ–≥–æ —Ç–∏–ø–∞ –¥–∞–Ω–Ω—ã—Ö')
            '''–ï—Å–ª–∏ –µ—Å—Ç—å —ç–ª–µ–º–µ–Ω—Ç, –Ω–µ —è–≤–ª—è—é—â–∏–π—Å—è —Å–ø–∏—Å–∫–æ–º/–∫–æ—Ä—Ç–µ–∂–µ–º, –≤—ã–≤–æ–¥–∏—Ç –æ—à–∏–±–∫—É'''

    return new_mat
```
![–ó–∞–¥–∞–Ω–∏–µ 1(flatten)](/images/lab02/01_arrays_flatten.png)

### –ó–∞–¥–∞–Ω–∏–µ 2 (transpose)

```py
def transpose(mat: list[list[float | int]]) -> list[list]:

    if not mat:
        return []
        '''–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –≤ –º–∞—Ç—Ä–∏—Ü–µ'''
    
    for num in range(len(mat) - 1):
        if len(mat[num]) != len(mat[num + 1]):
            raise ValueError('–ú–∞—Ç—Ä–∏—Ü–∞ —Ä–≤–∞–Ω–∞—è')
            '''–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –æ–¥–∏–Ω–∞–∫–æ–≤—É—é –¥–ª–∏–Ω—É —Å—Ç—Ä–æ–∫'''

    len_row = len(mat[0])
    len_col = len(mat)
    new_mat =[]

    for col_ind in range(len_row):
        new_row = []
        '''
        C –∫–∞–∂–¥—ã–º –∑–∞–ø—É—Å–∫–æ–º —Ü–∏–∫–ª–∞ —Å–æ–∑–¥–∞—ë—Ç—Å—è —Ä—è–¥, —Ä—è–¥–æ–≤ —Å—Ç–æ–ª—å–∫–æ,
        —Å–∫–æ–ª—å–∫–æ —Å—Ç–æ–ª–±—Ü–æ–≤ –≤ –∏–∑–Ω–∞—á–∞–ª—å–Ω–æ–π –º–∞—Ç—Ä–∏—Ü–µ
        '''
        for row_ind in range(len_col):
            new_row.append(mat[row_ind][col_ind])
            '''
            –≠–ª–µ–º–µ–Ω—Ç–æ–≤ –≤ —Ä—è–¥ –¥–æ–±–∞–≤–ª—è–µ—Ç—Å—è —Å—Ç–æ–ª—å–∫–æ, —Å–∫–æ–ª—å–∫–æ
            —Å—Ç–æ–ª–±—Ü–æ–≤ –≤ –∏–∑–Ω–∞—á–∞–ª—å–Ω–æ–π –º–∞—Ç—Ä–∏—Ü–µ
            '''
        new_mat.append(new_row)
        '''–†—è–¥ –¥–æ–±–∞–≤–ª—è–µ—Ç—Å—è –≤ –Ω–æ–≤—É—é –º–∞—Ç—Ä–∏—Ü—É'''

    return new_mat
```
![–ó–∞–¥–∞–Ω–∏–µ 2(transpose)](/images/lab02/02_matrix_transpose.png)

### –ó–∞–¥–∞–Ω–∏–µ 2 (row_sums)

```py
def row_sums(mat: list[list[float | int]]) -> list[float]:
    
    for num in range(len(mat) - 1):
        if len(mat[num]) != len(mat[num + 1]):
            raise ValueError('–ú–∞—Ç—Ä–∏—Ü–∞ —Ä–≤–∞–Ω–∞—è')
            '''–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –æ–¥–∏–Ω–∞–∫–æ–≤—É—é –¥–ª–∏–Ω—É —Å—Ç—Ä–æ–∫'''

    sum_row = []

    for row in mat:
        sum_row.append(sum(row))

    return sum_row
```

![–ó–∞–¥–∞–Ω–∏–µ 2(row_sums)](/images/lab02/02_matrix_row_sums.png)

### –ó–∞–¥–∞–Ω–∏–µ 2 (col_sums)

```py
def col_sums(mat: list[list[float | int]]) -> list[float]:

    len_row = len(mat[0])
    len_col = len(mat)
    
    for num in range(len(mat) - 1):
        if len(mat[num]) != len(mat[num + 1]):
            raise ValueError('–ú–∞—Ç—Ä–∏—Ü–∞ —Ä–≤–∞–Ω–∞—è')
            '''–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –æ–¥–∏–Ω–∞–∫–æ–≤—É—é –¥–ª–∏–Ω—É —Å—Ç—Ä–æ–∫'''

    sum_col = []

    for col in range(len_row):
        summa = 0
        for row in range(len_col):
            summa += mat[row][col] #–º–µ–Ω—è–µ–º –∏–Ω–¥–µ–∫—Å—ã –º–µ—Å—Ç–∞–º–∏
        sum_col.append(summa)
    
    return sum_col
```

![–ó–∞–¥–∞–Ω–∏–µ 2(col_sums)](/images/lab02/02_matrix_col_sums.png)

### –ó–∞–¥–∞–Ω–∏–µ 3 (tuples)

```py
def format_record(rec: tuple[str, str, float]) -> str:

    fio = rec[0].title().split()
    if fio == [] or len(fio) == 1 or rec[1] == [] or rec[2] == []:
        raise ValueError("–ü—É—Å—Ç—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è")
    '''ValueError, –µ—Å–ª–∏ –ø—É—Å—Ç—ã–µ –∏–º—è/–≥—Ä—É–ø–ø–∞/GPA'''

   if  not isinstance(rec[0], str) or not isinstance(rec[1], str) or not isinstance(rec[2], float) :
        if not isinstance(rec, tuple):
            raise TypeError('–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Ç–∏–ø –¥–∞–Ω–Ω—ã—Ö')
    '''TypeError, –µ—Å–ª–∏ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Ç–∏–ø –¥–∞–Ω–Ω—ã—Ö'''
    

    if len(fio) == 3:
        f_io = f"{fio[0]} {fio[1][0]}. {fio[2][0]}."
    else:
        f_io = f"{fio[0]} {fio[1][0]}."
    """–í 1 —ç–ª–µ–º–µ–Ω—Ç–µ –∫–æ—Ä—Ç–µ–∂–∞ –≤—Å–µ 1 –±—É–∫–≤—ã —Å—Ç–∞–Ω–æ–≤—è—Ç—Å—è –ø—Ä–æ–ø–∏—Å–Ω—ã–º–∏,
       –≤ f_io —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è —Ñ–∞–º–∏–ª–∏—è –∏ –∏–Ω–∏—Ü–∏–∞–ª—ã"""
    
    GPA = f'GPA {format(round(rec[2], 2), '.2f')}'
    '''–û–∫—Ä—É–≥–ª–µ–Ω–∏–µ (round), 2 –∑–Ω–∞–∫–∞ –ø–æ—Å–ª–µ –∑–∞–ø—è—Ç–æ–π(format)'''

    return f'{f_io}, –≥—Ä. {rec[1]}, {GPA}'

print(format_record(("–ò–≤–∞–Ω–æ–≤ –ò–≤–∞–Ω –ò–≤–∞–Ω–æ–≤–∏—á", "BIVT-25", 4.6)))
print(format_record(("–ü–µ—Ç—Ä–æ–≤ –ü—ë—Ç—Ä", "IKBO-12", 5.0)))
print(format_record(("–ü–µ—Ç—Ä–æ–≤ –ü—ë—Ç—Ä –ü–µ—Ç—Ä–æ–≤–∏—á", "IKBO-12", 5.0)))
print(format_record(("  —Å–∏–¥–æ—Ä–æ–≤–∞  –∞–Ω–Ω–∞   —Å–µ—Ä–≥–µ–µ–≤–Ω–∞ ", "ABB-01", 3.999)))
```

![–ó–∞–¥–∞–Ω–∏–µ 3 (tuples)](/images/lab02/02_tuples.png)



## LAB_03

### –ó–∞–¥–∞–Ω–∏–µ 1 (normalize)

```py
def normalize(text: str, *, casefold: bool = True, yo2e: bool = True) -> str:

    '''
    –ï—Å–ª–∏ casefold=True ‚Äî –ø—Ä–∏–≤–µ—Å—Ç–∏ –∫ casefold (–ª—É—á—à–µ, —á–µ–º lower –¥–ª—è –Æ–Ω–∏–∫–æ–¥–∞).
    –ï—Å–ª–∏ yo2e=True ‚Äî –∑–∞–º–µ–Ω–∏—Ç—å –≤—Å–µ —ë/–Å –Ω–∞ –µ/–ï.
    –£–±—Ä–∞—Ç—å –Ω–µ–≤–∏–¥–∏–º—ã–µ —É–ø—Ä–∞–≤–ª—è—é—â–∏–µ —Å–∏–º–≤–æ–ª—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä, \t, \r) ‚Üí
    –∑–∞–º–µ–Ω–∏—Ç—å –Ω–∞ –ø—Ä–æ–±–µ–ª—ã, —Å—Ö–ª–æ–ø–Ω—É—Ç—å –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è –ø—Ä–æ–±–µ–ª—ã –≤ –æ–¥–∏–Ω.
    '''

    if casefold == True:
        text = text.casefold()    # —Å—Ç—Ä–æ–∫—É –≤ –Ω–∏–∂–Ω–∏–π —Ä–µ–≥–∏—Å—Ç—Ä

    if yo2e == True:
        text = text.replace('—ë', '–µ')
    
    text = text.replace('\t', ' ').replace('\n', ' ').replace('\r', ' ')
    norm = ' '.join(text.split())
    '''
    C–ø–ª–∏—Ç–æ–º —É–±–∏—Ä–∞–µ–º –≤—Å–µ –ø—Ä–æ–±–µ–ª—ã; –ø–æ–ª—É—á–∏–≤—à–∏–π—Å—è —Å–ø–∏—Å–æ–∫ –º–µ—Ç–æ–¥–æ–º
    " ".join() —Å–Ω–æ–≤–∞ –ø—Ä–µ–≤—Ä–∞—â–∞–µ–º –≤ —Å—Ç—Ä–æ–∫—É
    '''
    return norm

assert normalize("–ü—Ä–ò–≤–ï—Ç\n–ú–ò—Ä\t") == "–ø—Ä–∏–≤–µ—Ç –º–∏—Ä"
assert normalize("—ë–∂–∏–∫, –Å–ª–∫–∞") == "–µ–∂–∏–∫, –µ–ª–∫–∞"
assert normalize("Hello\r\nWorld") == "hello world"
assert normalize("  –¥–≤–æ–π–Ω—ã–µ   –ø—Ä–æ–±–µ–ª—ã  ") == "–¥–≤–æ–π–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã"

```

![–ó–∞–¥–∞–Ω–∏–µ 1 (normalize)](/images/lab03/01_text_normalize.png)

### –ó–∞–¥–∞–Ω–∏–µ 1 (tokenize)

```py
import re  

def tokenize(text: str) -> list[str]:
    '''
    –†–∞–∑–±–∏—Ç—å –Ω–∞ ¬´—Å–ª–æ–≤–∞¬ª –ø–æ –Ω–µ–±—É–∫–≤–µ–Ω–Ω–æ-—Ü–∏—Ñ—Ä–æ–≤—ã–º —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è–º.
    –í –∫–∞—á–µ—Å—Ç–≤–µ —Å–ª–æ–≤–∞ —Å—á–∏—Ç–∞–µ–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Å–∏–º–≤–æ–ª–æ–≤ \w 
    (–±—É–∫–≤—ã/—Ü–∏—Ñ—Ä—ã/–ø–æ–¥—á—ë—Ä–∫–∏–≤–∞–Ω–∏–µ) –ø–ª—é—Å –¥–µ—Ñ–∏—Å –≤–Ω—É—Ç—Ä–∏ —Å–ª–æ–≤–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É).
    –ß–∏—Å–ª–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, 2025) —Å—á–∏—Ç–∞–µ–º —Å–ª–æ–≤–∞–º–∏.

    –ú–Ω–æ–∂–µ—Å—Ç–≤–æ —Å–ª–æ–≤ ‚Äî —ç—Ç–æ –≤—Å–µ –ø–æ–¥—Å—Ç—Ä–æ–∫–∏, —É–¥–æ–≤–ª–µ—Ç–≤–æ—Ä—è—é—â–∏–µ —à–∞–±–ª–æ–Ω—É
    \w+(?:-\w+)*
    (–±—É–∫–≤—ã/—Ü–∏—Ñ—Ä—ã/–ø–æ–¥—á—ë—Ä–∫–∏–≤–∞–Ω–∏–µ; –¥–æ–ø—É—Å–∫–∞–µ—Ç—Å—è –¥–µ—Ñ–∏—Å –≤–Ω—É—Ç—Ä–∏ —Å–ª–æ–≤–∞), —Ä–∞–∑–¥–µ–ª—ë–Ω–Ω—ã–µ
    –ª—é–±—ã–º–∏ –Ω–µ-\w —Å–∏–º–≤–æ–ª–∞–º–∏.
    '''
    key = r'\w+(?:-\w+)*'

    '''
    –†–µ–≥—É–ª—è—Ä–Ω–æ–µ –≤—ã—Ä–∞–∂–µ–Ω–∏–µ (–Ω–∞—Ö–æ–¥–∏—Ç –≤—Å–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è —à–∞–±–ª–æ–Ω—É '\w+(?:-\w+)*')
    –∏–º–µ–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É r'...':
    1) \w+ –æ–∑–Ω–∞—á–∞–µ—Ç –æ–¥–∏–Ω –∏–ª–∏ –±–æ–ª–µ–µ —Å–∏–º–≤–æ–ª–æ–≤ —Ç–∏–ø–∞ –±—É–∫–≤, —Ü–∏—Ñ—Ä, –ø–æ–¥—á—ë—Ä–∫–∏–≤–∞–Ω–∏–µ
    2) (?:...) - –Ω–µ–∑–∞—Ö–≤–∞—Ç—ã–≤–∞—é—â–∞—è –≥—Ä—É–ø–ø–∞. –¢–æ –µ—Å—Ç—å –≤—Å—ë, —á—Ç–æ –ø–æ—Å–ª–µ –¥–µ—Ñ–∏—Å–∞,
       –Ω–µ –±—É–¥–µ—Ç –∑–∞–ø–æ–º–∏–Ω–∞—Ç—å—Å—è –∫–∞–∫ –æ—Ç–¥–µ–ª—å–Ω–æ–µ —Å–ª–æ–≤–æ, –æ–Ω–æ –±—É–¥–µ—Ç –ø—Ä–∏—Å–æ–µ–¥–∏–Ω–µ–Ω–∏–Ω–æ –∫ –ø—Ä–µ–¥—ã–¥—É—â–µ–º—É –Ω–∞—Ö–æ–∂–¥–µ–Ω–∏—é.
    3) -\w+ - –±—É–∫–≤—ã –∏ —Ü–∏—Ñ—Ä—ã –ø–æ—Å–ª–µ –¥–µ—Ñ–∏—Å–∞
    4) * –æ–∑–Ω–∞—á–∞–µ—Ç –ª—é–±–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–¥–æ–±–Ω—ã—Ö –≤—Ö–æ–∂–¥–µ–Ω–∏–π (0-–±–µ—Å–∫–æ–Ω–µ—á–Ω–æ—Å—Ç—å)
    '''
    
    # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è —á–µ—Ä–µ–∑ findall. tokens - —ç—Ç–æ —Å–ø–∏—Å–æ–∫
    tokens = re.findall(key, text)
    
    return tokens

assert tokenize("–ø—Ä–∏–≤–µ—Ç, –º–∏—Ä!") == ["–ø—Ä–∏–≤–µ—Ç", "–º–∏—Ä"]
assert tokenize("–ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É –∫—Ä—É—Ç–æ") == ["–ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É", "–∫—Ä—É—Ç–æ"]
assert tokenize("2025 –≥–æ–¥") == ["2025", "–≥–æ–¥"]

```

![–ó–∞–¥–∞–Ω–∏–µ 1 (tokenize)](/images/lab03/01_text_tokenize.png)

### –ó–∞–¥–∞–Ω–∏–µ 1 (count_freq)

```py
def count_freq(tokens: list[str]) -> dict[str, int]:

    '''–ü–æ–¥—Å—á–∏—Ç–∞—Ç—å —á–∞—Å—Ç–æ—Ç—ã, –≤–µ—Ä–Ω—É—Ç—å —Å–ª–æ–≤–∞—Ä—å —Å–ª–æ–≤–æ ‚Üí –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ.'''

    freq = {} #—Å–æ–∑–¥–∞—ë–º —Å–ª–æ–≤–∞—Ä—å, –≤ –∫–æ—Ç–æ—Ä—ã–π –∏ –±—É–¥–µ–º –≤–Ω–æ—Å–∏—Ç—å —Å–ª–æ–≤–∞ –∏ —á–∞—Å—Ç–æ—Ç—ã

    for key in tokens: #–ø—Ä–æ–±–µ–≥–∞–µ–º—Å—è –ø–æ –∫–∞–∂–¥–æ–º—É —Ç–æ–∫–µ–Ω—É
        freq[key] = freq.get(key, 0) + 1
        '''get –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—É—â–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ, –µ—Å–ª–∏ –∫–ª—é—á —É–∂–µ –µ—Å—Ç—å –≤ —Å–ª–æ–≤–∞—Ä–µ + 1
           –∏–ª–∏ 0 + 1, –µ—Å–ª–∏ –≤ —Å–ª–æ–≤–∞—Ä–µ –∫–ª—é—á–∞ –µ—â–µ –Ω–µ—Ç –≤ —Å–ª–æ–≤–∞—Ä–µ. –û–Ω –ø–æ—è–≤–ª—è–µ—Ç—è —Ç–∞–º –≤ –≤–∏–¥–µ {key:1} '''

    return freq

freq = count_freq(["a","b","a","c","b","a"])
assert freq == {"a":3, "b":2, "c":1}
```

![–ó–∞–¥–∞–Ω–∏–µ 1 (count_freq)](/images/lab03/01_text_count_freq.png)


### –ó–∞–¥–∞–Ω–∏–µ 1 (top_n)

```py
def top_n(freq: dict[str, int], n: int = 2) -> list[tuple[str, int]]:

    '''–í–µ—Ä–Ω—É—Ç—å —Ç–æ–ø-N –ø–æ —É–±—ã–≤–∞–Ω–∏—é —á–∞—Å—Ç–æ—Ç—ã; –ø—Ä–∏ —Ä–∞–≤–µ–Ω—Å—Ç–≤–µ ‚Äî –ø–æ –∞–ª—Ñ–∞–≤–∏—Ç—É —Å–ª–æ–≤–∞.'''

    sorted_items = sorted(freq.items())
    sorted_items = sorted(sorted_items, key = lambda x : x[1], reverse = True)
    '''
    –°–æ—Ä—Ç–∏—Ä—É–µ–º —Å–ª–æ–≤–∞—Ä—å —Å–Ω–∞—á–∞–ª–∞ –ø–æ –∞–ª—Ñ–∞–≤–∏—Ç—É, –ø–æ—Ç–æ–º —É–∂–µ –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å
    (—Ç–µ–ø–µ—Ä—å —Å–ø–∏—Å–æ–∫ –∫–æ—Ä—Ç–µ–∂–µ–π) —Å–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —á–∞—Å—Ç–æ—Ç–∞–º (reverse –¥–ª—è —Ç–æ–≥–æ, —á—Ç–æ–±—ã —Å–Ω–∞—á–∞–ª–∞
    –æ—Ç–æ–±—Ä–∞–∂–∞–ª—Å—è —Å–∞–º—ã–π –±–æ–ª—å—à–æ–π).
    –ß—Ç–æ –¥–µ–ª–∞–µ—Ç lambda x: –º–∏–Ω–∏-—Ñ—É–Ω–∫—Ü–∏—è, –∫–æ—Ç–æ—Ä–∞—è –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —ç–ª–µ–º–µ–Ω—Ç x[1] –∫–æ—Ä—Ç–µ–∂–∞ ('—Å–ª–æ–≤–æ', —á–∞—Å—Ç–æ—Ç–∞)
    => –æ–Ω —Å—Ç–∞–Ω–æ–≤–∏—Ç—Å—è –∫–ª—é—á–æ–º. –ü–µ—Ä–≤–∞—è —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç –∏ –±–µ–∑ –∫–ª—é—á–∞, —Ç–∞–∫ –∫–∞–∫ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    —Ñ—É–Ω–∫—Ü–∏—è sorted —Å–æ—Ä—Ç–∏—Ä—É–µ—Ç –ø–æ 1 —ç–ª–µ–º–µ–Ω—Ç—É (–≤ –Ω–∞—à–µ–º —Å–ª—É—á–∞—é - –ø–æ –∫–ª—é—á—É)
    '''

    return sorted_items[:n]
    '''–í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø–µ—Ä–≤—ã–µ n —ç–ª–µ–º–µ–Ω—Ç–æ–≤ —Å—Ä–µ–∑–æ–º'''

freq = count_freq(["a","b","a","c","b","a"])
assert top_n(freq, 2) == [("a",3), ("b",2)]
```

![–ó–∞–¥–∞–Ω–∏–µ 1 (top_n)](/images/lab03/01_text_top_n.png)

### –ó–∞–¥–∞–Ω–∏–µ 2 (text_stats)

```py
import sys   #–∏–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Å–∏—Å—Ç–µ–º—É, —á—Ç–æ–±—ã –ø—Ä–∏–º–µ–Ω–∏—Ç—å –≤–≤–æ–¥ stdin –∏ –¥–æ–±–∞–≤–∏—Ç—å –ø—É—Ç—å –∫ –ø–∞–ø–∫–µ
sys.path.append('C:/Users/user/Desktop/python_labs/src')  #–¥–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –ø–∞–ø–∫–µ, —á—Ç–æ–±—ã –æ–Ω –Ω–∞—à–µ–ª –ø–∞–ø–∫—É lib
from lib.text import normalize, tokenize, count_freq, top_n

def main():

    line = sys.stdin.read()   #–ß–∏—Ç–∞–µ—Ç –≤–µ—Å—å –≤–≤–æ–¥ –¥–æ –∫–æ–Ω—Ü–∞ —Ñ–∞–π–ª–∞. –°trl+Z+Enter –¥–ª—è –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏—è –≤–≤–æ–¥–∞
    
    norm_line = tokenize(normalize(line))   #–±–µ–∑ —ç—Ç–æ–≥–æ —à–∞–≥–∞ —Å–ª–æ–≤–∞ –≤ –≤–µ—Ä—Ö–Ω–µ–º –∏ –Ω–∏–∂–Ω–µ–º —Ä–µ–≥–∏—Å—Ç—Ä–µ –±—É–¥—É—Ç —Å—á–∏—Ç–∞—Ç—å—Å—è —Ä–∞–∑–Ω—ã–º–∏
    uniq_line = len(set(norm_line))   #set –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤ (–±–µ–∑ –ø–æ–≤—Ç—Ä–æ–µ–Ω–∏–π)
    freq = count_freq(norm_line)
    top5 = top_n(freq, 5)


    print('–í—Å–µ–≥–æ —Å–ª–æ–≤:', len(norm_line))
    print('–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤:', uniq_line)
    print('–¢–æ–ø-5:')
    for i in top5:   #—Ü–∏–∫–ª –¥–ª—è –≤–≤–æ–¥–∞ –≤ i=5 —Å—Ç—Ä–æ–∫
        print( f'{i[0]}:{i[1]}') 

while True:  #–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ: –¥–ª—è –±–µ—Å–∫–æ–Ω–µ—á–Ω–æ–≥–æ –≤—ã–∑–æ–≤–∞ —Ñ—É–Ω–∫—Ü–∏–∏
    main()   #–≤—ã–∑–æ–≤ —Ñ—É–Ω–∫—Ü–∏–∏
```
![–ó–∞–¥–∞–Ω–∏–µ 2 (text_stats)](/images/lab03/02_text_stats.png) -->

<!-- ## LAB_04

### –ó–∞–¥–∞–Ω–∏–µ A (read_text)


```py
from pathlib import Path

def read_text(path: str | Path, encoding: str = "utf-8") -> str:

    '''
    –û—Ç–∫—Ä—ã—Ç—å —Ñ–∞–π–ª –Ω–∞ —á—Ç–µ–Ω–∏–µ –≤ —É–∫–∞–∑–∞–Ω–Ω–æ–π –∫–æ–¥–∏—Ä–æ–≤–∫–µ –∏ –≤–µ—Ä–Ω—É—Ç—å —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –∫–∞–∫ –æ–¥–Ω—É —Å—Ç—Ä–æ–∫—É.
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –æ—à–∏–±–∫–∏: –µ—Å–ª–∏ —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω ‚Äî –ø–æ–¥–Ω–∏–º–∞—Ç—å FileNotFoundError (–ø—É—Å—Ç—å –ø–∞–¥–∞–µ—Ç),
    –µ—Å–ª–∏ –∫–æ–¥–∏—Ä–æ–≤–∫–∞ –Ω–µ –ø–æ–¥—Ö–æ–¥–∏—Ç ‚Äî –ø–æ–¥–Ω–∏–º–∞—Ç—å UnicodeDecodeError (–ø—É—Å—Ç—å –ø–∞–¥–∞–µ—Ç).
    '''

    p = Path(path)   # –°–æ–∑–¥–∞–µ–º –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É - Path-–æ–±—ä–µ–∫—Ç
    
    if not p.exists():   # –Ø–≤–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è —Ñ–∞–π–ª–∞
        raise FileNotFoundError('–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω')

    '''
    UnicodeDecodeError –ø–æ–¥–Ω–∏–º–∞–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏.
    –î–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Ä–∞–∑—ã—Ö –∫–æ–¥–∏—Ä–æ–≤–æ–∫ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –ø—Ä–æ–ø–∏—Å–∞—Ç—å –≤ –≤—ã–∑–æ–≤–µ —Ñ—É–Ω–∫—Ü–∏–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä
    encoding=... . 
    –ü—Ä–∏–º–µ—Ä—ã:
    –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é UTF-8: read_text("file.txt")
    –¥—Ä—É–≥–∏–µ: read_text("file.txt", encoding="cp1251")
            read_text("file.txt", encoding="koi8-r")
    '''
    return p.read_text(encoding=encoding)

```
```py
import csv
from pathlib import Path
from typing import Iterable, Sequence

def write_csv(rows: Iterable[Sequence], path: str | Path, header: tuple[str, ...] | None = None) -> None:

    '''
    –°–æ–∑–¥–∞—Ç—å/–ø–µ—Ä–µ–∑–∞–ø–∏—Å–∞—Ç—å CSV —Å —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–º ,.
    –ï—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω header, –∑–∞–ø–∏—Å–∞—Ç—å –µ–≥–æ –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–æ–∫–æ–π.
    –ü—Ä–æ–≤–µ—Ä–∏—Ç—å, —á—Ç–æ –∫–∞–∂–¥–∞—è —Å—Ç—Ä–æ–∫–∞ –≤ rows –∏–º–µ–µ—Ç –æ–¥–∏–Ω–∞–∫–æ–≤—É—é –¥–ª–∏–Ω—É (–∏–Ω–∞—á–µ ValueError).
    '''

    p = Path(path)   # –°–æ–∑–¥–∞–µ–º –ø—É—Ç—å
    rows = list(rows)
    '''
    –ï—Å–ª–∏ –Ω–∞ –≤—Ö–æ–¥ —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ–¥–∞–≤–∞–ª—Å—è –Ω–µ —Å–ø–∏—Å–æ–∫, –∞ –¥—Ä—É–≥–æ–π –∏—Ç–µ—Ä–∏—Ä—É–µ–º—ã–π –æ–±—ä–µ–∫—Ç (–Ω–∞–ø—Ä–∏–º–µ—Ä, –∫–æ—Ä—Ç–µ–∂)
    - –ø—Ä–µ–≤—Ä–∞—â–∞–µ–º –µ–≥–æ –≤ —Å–ø–∏—Å–æ–∫. –§–∏–∫—Å–∏—Ä—É–µ—Ç –¥–∞–Ω–Ω—ã–µ –Ω–∞ –º–æ–º–µ–Ω—Ç –≤—ã–∑–æ–≤–∞ —Ñ—É–Ω–∫—Ü–∏–∏ —Å–æ–∑–¥–∞–Ω–∏–µ–º –Ω–æ–≤–æ–≥–æ —Å–ø–∏—Å–∫–∞.
    '''
    with p.open('w', newline='', encoding = 'utf-8') as f:
        '''
        –ß–µ—Ä–µ–∑ –º–µ–Ω–µ–¥–∂–µ—Ä –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ (–∞–≤—Ç–æ–∑–∞–∫—Ä—ã—Ç–∏–µ —Ñ–∞–π–ª–∞+—É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å –∫ –æ—à–∏–±–∫–∞–º) –æ—Ç–∫—Ä—ã–≤–∞–µ–º
        —Ñ–∞–π–ª –≤ —Ä–µ–∂–∏–º–µ 'w' - —á—Ç–µ–Ω–∏—è, –∫–æ–¥–∏—Ä–æ–≤–∫–∞ UTF-8. 
        newline="" –ø–æ–∑–≤–æ–ª—è–µ—Ç –∏–∑–±–∞–≤–∏—Ç—å—Å—è –æ—Ç –ø—Ä–æ–±–ª–µ–º –ø—Ä–∏ —Ä–∞–±–æ—Ç–µ —Å —Ñ–∞–π–ª–æ–º –≤ —Ä–∞–∑–Ω—ã—Ö –û–°.
        –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –ø–µ—Ä–µ–≤–æ–¥–∞ —Å—Ç—Ä–æ–∫
        '''
        w = csv.writer(f)   # –°–æ–∑–¥–∞–Ω–∏–µ –æ–±—ä–µ–∫—Ç–∞ writer –¥–ª—è –∑–∞–ø–∏—Å–∏ –≤ csv —Ñ–æ—Ä–º–∞—Ç
        if header is not None:
            w.writerow(header)   # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫, –µ—Å–ª–∏ —Ç–∞–∫–æ–π —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        
        if rows:    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–µ —Ä–∞–≤–Ω—É—é –¥–ª–∏–Ω—É —Å—Ç—Ä–æ–∫
            for r in rows:
                if len(r) != len(rows[0]):
                    raise ValueError("–°—Ç—Ä–æ–∫–∏ –∏–º–µ—é—Ç —Ä–∞–∑–Ω—É—é –¥–ª–∏–Ω—É!")

        for r in rows:
            w.writerow(r)   # –ó–∞–ø–∏—Å—ã–≤–∞–µ—Ç —Ä—è–¥—ã –ø–æ—Å—Ç—Ä–æ—á–Ω–æ

'''–§—É–Ω–∫—Ü–∏—è –Ω–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –Ω–∏—á–µ–≥–æ, –æ–Ω–∞ –∑–∞–ø–∏—Å—ã–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –≤ CSV —Ñ–∞–π–ª.'''
```
```py
from pathlib import Path

def ensure_parent_dir(path: Path | str) -> None:

    p = Path(path)
    parent_dir = p.parent
    
    '''
    –°–æ–∑–¥–∞—ë–º —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
    parents=True - —Å–æ–∑–¥–∞—ë—Ç –≤—Å–µ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
    exist_ok=True - –Ω–µ –≤—ã–∑—ã–≤–∞–µ—Ç –æ—à–∏–±–∫—É –µ—Å–ª–∏ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
    '''
    
    parent_dir.mkdir(parents=True, exist_ok=True)
```
![–ó–∞–¥–∞–Ω–∏–µ A](/images/lab04/01_io_txt_csv.png)

### –ó–∞–¥–∞–Ω–∏–µ B

```py
import sys   
sys.path.append('C:/Users/user/Desktop/python_labs/src')
from lib.text import normalize, tokenize, count_freq, top_n
from lib.io_txt_csv import read_text, write_csv, write_text


txt = read_text('data/input.txt')
txt = tokenize(normalize(txt))
txt_counts = top_n(count_freq(txt))
print('–í—Å–µ–≥–æ —Å–ª–æ–≤:', len(txt))
print('–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤:', len(set(txt)))
print('–¢–æ–ø-5:')
for i in txt_counts:  
    print( f'{i[0]}:{i[1]}') 

write_csv(txt_counts, 'data/report.csv', ("word","count"))
```

![–ó–∞–¥–∞–Ω–∏–µ B](/images/lab04/02_text_report.png)
 -->

<!-- 
## LAB_05

### –ó–∞–¥–∞–Ω–∏–µ A (json_to_csv)
```py
from pathlib import Path
import json
import csv
import sys
sys.path.append('C:/Users/user/Desktop/python_labs/')

def json_to_csv(json_path: str, csv_path: str) -> None:
    """
    –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç JSON-—Ñ–∞–π–ª –≤ CSV.
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π [{...}, {...}], –∑–∞–ø–æ–ª–Ω—è–µ—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –ø–æ–ª—è –ø—É—Å—Ç—ã–º–∏ —Å—Ç—Ä–æ–∫–∞–º–∏.
    –ö–æ–¥–∏—Ä–æ–≤–∫–∞ UTF-8. –ü–æ—Ä—è–¥–æ–∫ –∫–æ–ª–æ–Ω–æ–∫ ‚Äî –∫–∞–∫ –≤ –ø–µ—Ä–≤–æ–º –æ–±—ä–µ–∫—Ç–µ –∏–ª–∏ –∞–ª—Ñ–∞–≤–∏—Ç–Ω—ã–π (—É–∫–∞–∑–∞—Ç—å –≤ README).
    """
    json_path = Path(json_path)   # –°–æ–∑–¥–∞–µ–º –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É - Path-–æ–±—ä–µ–∫—Ç
    
    if not json_path.exists():   # –Ø–≤–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è –ø—É—Ç–∏
        raise FileExistsError('–ü—É—Ç—å –Ω–µ –Ω–∞–π–¥–µ–Ω')
    '''
    –†–∞–±–æ—Ç–∞–µ–º —Å –æ—Ç–∫—Ä—ã—Ç—ã–º JSON-—Ñ–∞–π–ª–æ–º –Ω–∞ —á—Ç–µ–Ω–∏–µ, –∑–∞–≥—Ä—É–∂–∞–µ–º –µ–≥–æ, –ø–∞—Ä–∞–ª–µ–ª–ª—å–Ω–æ –æ—Ç–ª–∞–≤–ª–∏–≤–∞—è –æ—à–∏–±–∫–∏.
    '''
    with open(json_path, 'r', encoding='utf-8') as json_file:
        try:
            data_json = json.load(json_file)

        except json.JSONDecodeError:   # –í—ã—Ö–æ–¥–∏—Ç, –∫–æ–≥–¥–∞ —Ñ–∞–π–ª –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ –∑–∞–≥—Ä—É–∑–∏—Ç—å –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON
            raise ValueError("–ü—É—Å—Ç–æ–π JSON –∏–ª–∏ –Ω–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞")
        
    if not data_json:  # –Ø–≤–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è —Ñ–∞–π–ª–∞
        raise FileNotFoundError("–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω")
        
    if not isinstance(data_json, list):
        raise ValueError('–§–∞–π–ª –Ω–µ JSON —Ñ–æ—Ä–º–∞—Ç–∞: –Ω–µ —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π')
        
    if not all(isinstance(row, dict) for row in data_json):
        raise ValueError('–§–∞–π–ª –Ω–µ JSON —Ñ–æ—Ä–º–∞—Ç–∞: –≤ —Å–ø–∏—Å–∫–µ –Ω–µ —Å–ª–æ–≤–∞—Ä–∏')
    '''
    –†–∞–±–æ—Ç–∞–µ–º —Å CSV-—Ñ–∞–π–ª–æ–º, –∑–∞–ø–∏—Å—ã–≤–∞—è –≤ –Ω–µ–≥–æ –¥–∞–Ω–Ω—ã–µ –∏–∑ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ —Ä–∞–Ω–µ–µ JSON-—Ñ–∞–π–ª–∞.
    '''

    csv_path = Path(csv_path)

    with open(csv_path, 'w', encoding='utf-8', newline='') as csv_file:
        writer = csv.DictWriter(csv_file, fieldnames=data_json[0].keys()) # –ó–∞–ø–∏—Å—ã–≤–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π, –∑–∞–≥–æ–ª–æ–≤–æ–∫ - –∫–ª—é—á–∏ —Å–ª–æ–≤–∞—Ä–µ–π
        writer.writeheader()
        writer.writerows(data_json) # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ—Å—Ç—Ä–æ—á–Ω–æ

```
![json_to_csv](/images/lab05/01_json_csv.png)

### –ó–∞–¥–∞–Ω–∏–µ A (csv_to_json)

```py
from pathlib import Path
import json
import csv
import sys
sys.path.append('C:/Users/user/Desktop/python_labs/')

def csv_to_json(csv_path: str, json_path: str) -> None:
    """
    –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç CSV –≤ JSON (—Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π).
    –ó–∞–≥–æ–ª–æ–≤–æ–∫ –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω, –∑–Ω–∞—á–µ–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –∫–∞–∫ —Å—Ç—Ä–æ–∫–∏.
    json.dump(..., ensure_ascii=False, indent=2)
    """

    csv_path = Path(csv_path)

    if not csv_path.exists():
        raise FileNotFoundError('–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω')
    
    if csv_path.suffix != '.csv':
            raise ValueError("–ù–µ–≤–µ—Ä–Ω—ã–π —Ç–∏–ø —Ñ–∞–π–ª–∞")
    '''
    –†–∞–±–æ—Ç–∞–µ–º —Å –æ—Ç–∫—Ä—ã—Ç—ã–º CSV-—Ñ–∞–π–ª–æ–º, –ø—Ä–æ–±—É–µ–º —á–∏—Ç–∞—Ç—å –∫–∞–∫ —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π –∏ –æ—Ç–ª–∞–≤–ª–∏–≤–∞–µ–º –æ—à–∏–±–∫–∏.
    '''
    with open(csv_path, 'r', encoding='utf-8') as csv_file:
        try:
            data_csv = csv.DictReader(csv_file)

        except data_csv.fieldnames is None:
            raise ValueError('–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –∑–∞–≥–æ–ª–æ–≤–∫–∏')
        
        if len(list(data_csv)) == 0:
             raise ValueError("–ü—É—Å—Ç–æ–π —Ñ–∞–π–ª")
        data_csv = list(data_csv) # –°–æ–∑–¥–∞—ë—Ç —Å–ø–∏—Å–æ–∫ –¥–∞–Ω–Ω—ã—Ö, —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Å—á–∏—Ç–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ

    json_path = Path(json_path)
    '''
    –†–∞–±–æ—Ç–∞–µ–º —Å JSON-—Ñ–∞–π–ª–æ–º, –∑–∞–≥—Ä—É–∂–∞—è –≤ –Ω–µ–≥–æ –¥–∞–Ω–Ω—ã–µ –∏–∑ CSV_—Ñ–∞–π–ª–∞.
    '''
    with open(json_path, 'w', encoding='utf-8') as json_file:
        json.dump(json.dump(data_csv, json_file, ensure_ascii=False, indent=2))
        '''
        data_csv - —á—Ç–æ –∑–∞–ø–∏—Å—ã–≤–∞–µ–º
        json_file -  –∫—É–¥–∞ –∑–∞–ø–∏—Å—ã–≤–∞–µ–º
        ensure_ascii=False - –∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞—è —Ä–∞–±–æ—Ç–∞ —Å –∫–∏—Ä–∏–ª–ª–∏—Ü–µ–π
        indent=2 - –∫—Ä–∞—Å–∏–≤—ã–π –≤—ã–≤–æ–¥
        '''
```
![csv_to_json](/images/lab05/01_csv_json.png)

### –ó–∞–¥–∞–Ω–∏–µ B (csv_to_xlsx)
```py
from pathlib import Path
import csv
from openpyxl import Workbook
from openpyxl.utils import get_column_letter # –£—Ç–∏–ª–∏—Ç–∞ openpyxl –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –±—É–∫–≤—ã —Å—Ç–æ–ª–±—Ü–∞ —Ç–∞–±–ª–∏—Ü—ã

def csv_to_xlsx(csv_path: str, xlsx_path: str) -> None:
    """
    –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç CSV –≤ XLSX.
    –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å openpyxl –ò–õ–ò xlsxwriter.
    –ü–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞ CSV ‚Äî –∑–∞–≥–æ–ª–æ–≤–æ–∫.
    –õ–∏—Å—Ç –Ω–∞–∑—ã–≤–∞–µ—Ç—Å—è "Sheet1".
    –ö–æ–ª–æ–Ω–∫–∏ ‚Äî –∞–≤—Ç–æ—à–∏—Ä–∏–Ω–∞ –ø–æ –¥–ª–∏–Ω–µ —Ç–µ–∫—Å—Ç–∞ (–Ω–µ –º–µ–Ω–µ–µ 8 —Å–∏–º–≤–æ–ª–æ–≤).
    """

    csv_path = Path(csv_path)
    xlsx_path = Path(xlsx_path)

    if not csv_path.exists():  # –Ø–≤–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è —Ñ–∞–π–ª–∞
        raise FileNotFoundError('–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω')
    
    if not xlsx_path.exists():  # –Ø–≤–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è —Ñ–∞–π–ª–∞
        raise FileNotFoundError('–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω')
    
    if csv_path.suffix != '.csv':
            raise ValueError("–ù–µ–≤–µ—Ä–Ω—ã–π —Ç–∏–ø —Ñ–∞–π–ª–∞")
    '''
    –†–∞–±–æ—Ç–∞–µ–º —Å CSV-—Ñ–∞–π–ª–æ–º, —á–∏—Ç–∞–µ–º –∏–∑ –Ω–µ–≥–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏ –ø—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –æ—à–∏–±–æ–∫. –ï—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å - –æ–Ω–∏ –≤—Å–ø–ª—ã–≤–∞—é—Ç.
    '''
    with open(csv_path, 'r', encoding='utf-8') as csv_file:
        reader = csv.DictReader(csv_file)
        csv_file = list(reader) # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—á–∏—Ç–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ —Å–ø–∏—Å–æ–∫
        if len(csv_file) == 0:
             raise ValueError("–ü—É—Å—Ç–æ–π —Ñ–∞–π–ª")
        
        if not reader.fieldnames:
             raise ValueError('–§–∞–π–ª –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤')
        
        wb = Workbook()      # –°–æ–∑–¥–∞–µ–º —Ä–∞–±–æ—á—É—é –∫–Ω–∏–≥—É
        ws = wb.active       # –°–æ–∑–¥–∞—ë–º –≤ –Ω–µ–π –Ω–æ–≤—ã–π –ª–∏—Å—Ç
        ws.title = "Sheet1"  # –ù–∞–∑—ã–≤–∞–µ–º –µ–≥–æ

        ws.append(reader.fieldnames)  # –î–æ–±–∞–≤–ª—è–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
        for row in csv_file:
            ws.append([row[field] for field in reader.fieldnames])  # –í –∫–∞–∂–¥—É—é —Å—Ç—Ä–æ–∫—É —Ç–∞–±–ª–∏—Ü—ã –¥–æ–±–∞–≤–ª—è–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â—É—é –µ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
        
        for column in ws.columns:   # –†–∞–≤–Ω—è–µ–º –≤—Å—ë –ø–æ —à–∏—Ä–∏–Ω–µ, 8 - –º–∏–Ω–∏–º—É–º
            max_length = 8
            column_letter = get_column_letter(column[0].column)
            for cell in column:
                max_length = max(len(str(cell.value)), max_length)

            ws.column_dimensions[column_letter].width = max_length
            

    wb.save(xlsx_path)  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Å–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ —É–∫–∞–∑–∞–Ω–Ω–æ–º –ø—É—Ç–∏
```
![csv_to_xlsx](/images/lab05/02_csv_to_xlsx.png) -->

## LAB_06
### CLI_text
```py
import argparse
from pathlib import Path
from src.lib.text import tokenize, count_freq, top_n

def main():

    parser = argparse.ArgumentParser(description='CLI-—É—Ç–∏–ª–∏—Ç—ã –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–æ–π ‚Ññ6')
    '''–°–æ–∑–¥–∞–µ—Ç –æ—Å–Ω–æ–≤–Ω–æ–π –ø–∞—Ä—Å–µ—Ä –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ —Å –æ–ø–∏—Å–∞–Ω–∏–µ–º'''
    subparsers = parser.add_subparsers(dest='command')
    '''–°–æ–∑–¥–∞–µ—Ç –ø–æ–¥–∫–æ–º–∞–Ω–¥—ã - –≤ –¥–∞–ª—å–Ω–µ–π—à–µ–º cat –∏ stats'''

    # –ü–æ–¥–∫–æ–º–∞–Ω–¥–∞ cat - —É—Ç–∏–ª–∏—Ç–∞ –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤ –≤ —Ç–µ—Ä–º–∏–Ω–∞–ª–µ.
    cat_parser = subparsers.add_parser("cat", help="–í—ã–≤–µ—Å—Ç–∏ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞")
    cat_parser.add_argument("--input", required=True, help="–ü—É—Ç—å –∫ –≤—Ö–æ–¥–Ω–æ–º—É —Ñ–∞–π–ª—É")
    cat_parser.add_argument("-n", action="store_true", help="–ù—É–º–µ—Ä–æ–≤–∞—Ç—å —Å—Ç—Ä–æ–∫–∏")
    '''action="store_true" - –µ—Å–ª–∏ —Ñ–ª–∞–≥ —É–∫–∞–∑–∞–Ω, –∑–Ω–∞—á–µ–Ω–∏–µ —Å—Ç–∞–Ω–æ–≤–∏—Ç—Å—è True, –∏–Ω–∞—á–µ False'''

    # –ü–æ–¥–∫–æ–º–∞–Ω–¥–∞ stats -  —É—Ç–∏–ª–∏—Ç–∞ –¥–ª—è –∞–¥–∞–ª–∏–∑–∞ —Ç–µ–∫—Å—Ç–æ–≤–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
    stats_parser = subparsers.add_parser("stats", help="–ß–∞—Å—Ç–æ—Ç—ã —Å–ª–æ–≤")
    stats_parser.add_argument("--input", required=True)
    stats_parser.add_argument("--top", type=int, default=5)
    '''type=int - –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –≤–≤–µ–¥–µ–Ω–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –≤ —á–∏—Å–ª–æ, –ø–æ –¥–µ—Ñ–æ–ª—Ç—É
       –≤—ã–≤–æ–¥–∏—Ç —Ç–æ–ø-5'''
    
    args = parser.parse_args() # "–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç" –∑–Ω–∞—á–µ–Ω–∏—è –Ω–∞ –≤—Ö–æ–¥–µ

    file = Path(args.input)

    if args.command == "cat":
        with open(file, 'r', encoding='utf-8') as f:
            count = 1
            for line in f: # –ü–æ—Å—Ç—Ä–æ—á–Ω–æ–µ —á—Ç–µ–Ω–∏–µ —Ñ–∞–π–ª–∞
                line = line.rstrip("\n") # –û—á–∏—â–∞–µ–º —Å—Ç—Ä–æ–∫—É –æ—Ç —Å–∏–º–≤–æ–ª–∞ –ø–µ—Ä–µ–Ω–æ—Å–∞
                if args.n: # –ï—Å–ª–∏ —É–∫–∞–∑–∞–Ω —Ñ–ª–∞–≥ -n, —Ç–æ –ø—Ä–æ–≤–æ–¥–∏–º –Ω—É–º–µ—Ä–∞—Ü–∏—é —Å—Ç—Ä–æ–∫
                    print(f'{count}: {line}')
                    count += 1
                else:
                    print(line)
            
    elif args.command == 'stats':
        with open(file, 'r', encoding='utf-8') as f:
            file = [i for i in f]
            tokens = tokenize(''.join(file))
            freq = count_freq(tokens)
            top = top_n(freq, n = args.top)
            '''–†–∞–±–æ—Ç–∞–µ–º —Å –≤—Ö–æ–¥–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏'''

            num = 1
    
            for word, count in top:
                print(f'{num}. {word} - {count}')
                num += 1

# –¢–æ—á–∫–∞ - –∑–∞–ø—É—Å–∫ –ø—Ä–æ–≥—Ä–∞–º–º—ã
if __name__ == "__main__":
    main()
```
![cat](images/lab06/cli_cat.png)
![stats](images/lab06/cli_stats.png)

### CLI_convert

```py
import argparse
import sys
from src.lab05.json_to_csv import json_to_csv
from src.lab05.csv_to_json import csv_to_json
from src.lab05.csv_to_xlsx import csv_to_xlsx

def main():
    parser = argparse.ArgumentParser(description="–ö–æ–Ω–≤–µ—Ä—Ç–µ—Ä—ã –¥–∞–Ω–Ω—ã—Ö")
    sub = parser.add_subparsers(dest="command")

    p1 = sub.add_parser("json2csv")
    p1.add_argument("--in", dest="input", required=True)
    p1.add_argument("--out", dest="output", required=True)

    p2 = sub.add_parser("csv2json")
    p2.add_argument("--in", dest="input", required=True)
    p2.add_argument("--out", dest="output", required=True)

    p3 = sub.add_parser("csv2xlsx")
    p3.add_argument("--in", dest="input", required=True)
    p3.add_argument("--out", dest="output", required=True)

    args = parser.parse_args() # "–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç" –∑–Ω–∞—á–µ–Ω–∏—è –Ω–∞ –≤—Ö–æ–¥–µ

    if args.command == "json2csv":
        # Python -m src.lab06.cli_convert json2csv --in data/samples/people.json --out data/out/people_from_json.csv
        json_to_csv(json_path=args.input, csv_path=args.output)

    if args.command == "csv2json":
        # Python -m src.lab06.cli_convert csv2json --in data/samples/people.csv --out data/out/people_from_csv.json
        csv_to_json(csv_path=args.input, json_path=args.output)

    if args.command == "csv2xlsx":
        # Python -m src.lab06.cli_convert csv2xlsx --in data/samples/cities.csv --out data/out/cities.xlsx
        csv_to_xlsx(csv_path=args.input, xlsx_path=args.output)

if __name__ == "__main__":
    main()
```
![csv2json](images/lab06/csv2json.png)
![csv2xlsx](images/lab06/csv2xlsx.png)
![json2csv](images/lab06/json2csv.png)

## LAB_07

### –ü—Ä–µ–¥—É—Å—Ç–∞–Ω–æ–≤–∫–∏
> –î–æ–±–∞–≤–∏—Ç—å —Ñ–∞–π–ª pyproject.toml –¥–ª—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–æ–≤–µ–¥–µ–Ω–∏—è —Ç–µ—Å—Ç–æ–≤. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å pytest –∏ black, —Å–æ–≤–º–µ—Å—Ç–∏–º—ã–µ —Å –≤–µ—Ä—Å–∏–µ–π Python

### –ó–∞–¥–∞–Ω–∏–µ A: test_text
```py
import pytest
import sys
from src.lib.text import normalize, tokenize, count_freq, top_n


""" –ü—Ä–æ–≤–æ–¥–∏–º –ø–∞—Ä–∞–º–µ—Ç—Ä–∏–∑–∞—Ü–∏—é, –¥–∞–ª–µ–µ - –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–µ—Å—Ç–∞. """
@pytest.mark.parametrize(
    "source, expected",
    [
        ("–ü—Ä–ò–≤–ï—Ç\n–ú–ò—Ä\t", "–ø—Ä–∏–≤–µ—Ç –º–∏—Ä"),
        ("—ë–∂–∏–∫, –Å–ª–∫a", "–µ–∂–∏–∫, –µ–ª–∫a"),
        ("Hello\r\nWorld", "hello world"),
        ("  –¥–≤–æ–π–Ω—ã–µ   –ø—Ä–æ–±–µ–ª—ã  ", "–¥–≤–æ–π–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã"),
        ("", "")
    ],
)
def test_normalize_basic(source, expected):
    assert normalize(source) == expected


@pytest.mark.parametrize(
    "source, expected",
    [
        ("–ø—Ä–∏–≤–µ—Ç, –º–∏—Ä!", ["–ø—Ä–∏–≤–µ—Ç", "–º–∏—Ä"]),
        ("–ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É –∫—Ä—É—Ç–æ", ["–ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É", "–∫—Ä—É—Ç–æ"]),   # —Ä–∞–±–æ—Ç–∞ —Å –¥–µ—Ñ–∏—Å–æ–º
        ("2025 –≥–æ–¥", ["2025", "–≥–æ–¥"]),   # —á—Ç–µ–Ω–∏–µ 
        ("emoji üòÄ –Ω–µ —Å–ª–æ–≤–æ", ["emoji", "–Ω–µ", "—Å–ª–æ–≤–æ"]),    # —É–¥–∞–ª–µ–Ω–∏–µ —ç–º–æ–¥–∂–∏
        ("    –º–Ω–æ–æ–æ–æ–æ–æ–≥–æ –Ω–µ–Ω—É–∂–Ω–æ–≥–æ!!", ["–º–Ω–æ–æ–æ–æ–æ–æ–≥–æ", "–Ω–µ–Ω—É–∂–Ω–æ–≥–æ"]),
        ("", [])   # –ø—É—Å—Ç–æ–π -> –ø—É—Å—Ç–æ–π
    ],
)
def test_tokenize_basic(source, expected):
    assert tokenize(source) == expected
    
@pytest.mark.parametrize(
    "tokens, expected",
    [
        (["a", "b", "a", "c", "b", "a"], {"a": 3, "b": 2, "c": 1}),
        ([], {}),   # –ø—É—Å—Ç–æ–π -> –ø—É—Å—Ç–æ–π
        (["test", "test", "test"], {"test": 3}),   #–æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ —Å–ª–æ–≤–∞
        (["üåç", "üöÄ", "üåç"], {"üåç": 2, "üöÄ": 1})   # –æ–±—Ä–∞–±–æ—Ç–∫–∞ —ç–º–æ–¥–∑–∏
    ],
)

def test_count_freq_and_top_n(tokens, expected):
    assert count_freq(tokens) == expected

@pytest.mark.parametrize(
        "words, n, expected",
    [
        ({"b": 5, "a": 5, "c": 3, "d": 2}, 2, [("a", 5), ("b", 5)]),  # —Ä–∞–≤–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è -> –ø–æ –∞–ª—Ñ–∞–≤–∏—Ç—É
        ({"x": 10}, 5, [("x", 10)]),   # n > dicts
        ({}, 3, []),   # –ø—É—Å—Ç–æ–π -> –ø—É—Å—Ç–æ–π
        ({"a": 1, "b": 1}, 0, []),   # n = 0
    ]
)
def test_top_n_tie_breaker(words, n, expected):
    assert top_n(words, n) == expected
```
![text](../../images/lab07/text.png)


### –ó–∞–¥–∞–Ω–∏–µ B: json2csv –∏ csv2json
```py
import pytest
from pathlib import Path
import sys
import json, csv
from src.lab05.csv_to_json import json_to_csv, csv_to_json



"""
–° –ø–æ–º–æ—â—å—é —Ñ–∏–∫—Å—Ç—É—Ä—ã tmp_path —Å–æ–∑–¥–∞—ë–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã –¥–ª—è —á—Ç–µ–Ω–∏—è –∏ –∑–∞–ø–∏—Å—ã –¥–∞–Ω–Ω—ã—Ö.
1 —Ç–µ—Å—Ç - –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç–∏ –∑–∞–ø–∏—Å–∏ –±–∞–∑–æ–≤–æ–≥–æ —Å–ª—É—á–∞—è
"""
def test_json_to_csv_roundtrip(tmp_path: Path):
    src = tmp_path / "people.json"
    dst = tmp_path / "people.csv"
    data = [
        {"name": "Alice", "age": 22},
        {"name": "Bob", "age": 25},
    ]
    src.write_text(json.dumps(data, ensure_ascii=False, indent=2), encoding="utf-8")
    json_to_csv(str(src), str(dst))

    with dst.open(encoding="utf-8") as f:
        rows = list(csv.DictReader(f))

    assert len(rows) == 2
    assert {"name", "age"} <= set(rows[0].keys())

"""–ü—É—Å—Ç–æ–π —Ñ–∞–π–ª"""
def test_json_to_csv_empty_file(tmp_path: Path):
    src = tmp_path / "people.json"
    dst = tmp_path / "people.csv"
    data = []
    src.write_text(json.dumps(data, ensure_ascii=False, indent=2), encoding="utf-8")


    with pytest.raises(ValueError, match="–ü—É—Å—Ç–æ–π —Ñ–∞–π–ª"):
        json_to_csv(str(src), str(dst))

"""–ù–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –ø—É—Ç—å"""
def test_json_to_csv_empty_file(tmp_path: Path):
    src = tmp_path / "nothing.json"
    dst = tmp_path / "people.csv"

    with pytest.raises(FileNotFoundError, match="–ü—É—Ç—å –Ω–µ –Ω–∞–π–¥–µ–Ω"):
        json_to_csv(str(src), str(dst))

"""1 –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∞"""
def test_json_to_csv_not_list(tmp_path: Path):
    src = tmp_path / "people.json"
    dst = tmp_path / "people.csv"
    data = {"name": "Alice", "age": 22}
    
    src.write_text(json.dumps(data, ensure_ascii=False, indent=2), encoding="utf-8")

    with pytest.raises(ValueError, match="–§–∞–π–ª –Ω–µ JSON —Ñ–æ—Ä–º–∞—Ç–∞: –Ω–µ —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π"):
        json_to_csv(str(src), str(dst))

"""2 –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∞"""
def test_json_to_csv_not_dict(tmp_path: Path):
    src = tmp_path / "people.json"
    dst = tmp_path / "people.csv"
    data = ['name": "Alice", "age": 22', 'name": "Bob", "age": 25']
    
    src.write_text(json.dumps(data, ensure_ascii=False, indent=2), encoding="utf-8")

    with pytest.raises(ValueError, match="–§–∞–π–ª –Ω–µ JSON —Ñ–æ—Ä–º–∞—Ç–∞: –≤ —Å–ø–∏—Å–∫–µ –Ω–µ —Å–ª–æ–≤–∞—Ä–∏"):
        json_to_csv(str(src), str(dst))


"""–ê–Ω–∞–ª–æ–≥–∏—á–Ω–æ –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–≥–æ –ø–µ—Ä–µ–≤–æ–¥–∞"""
def test_csv_to_json_roundtrip(tmp_path: Path):
    src = tmp_path / "people.csv"
    dst = tmp_path / "people.json"

    csv_data = """name,age,city,email
–ê–Ω–Ω–∞ –ò–≤–∞–Ω–æ–≤–∞,28,–ú–æ—Å–∫–≤–∞,anna@example.com
–ü–µ—Ç—Ä –°–∏–¥–æ—Ä–æ–≤,35,–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥,petr@example.com"""

    src.write_text(csv_data, encoding="utf-8")

    csv_to_json(str(src), str(dst))

    with dst.open('r', encoding="utf-8") as f:
        data = json.load(f)
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ 
    assert isinstance(data, list)
    assert len(data) == 2
    assert isinstance(data[0], dict)
    assert isinstance(data[1], dict)

# –ë—Ä–æ –≤–æ—Ç –µ—â–µ —Ç–µ—Å—Ç—ã –∏ —Ç–¥

"""–ü—É—Å—Ç–æ–π —Ñ–∞–π–ª"""
def test_csv_to_json_empty_file(tmp_path: Path):
    src = tmp_path / "people.csv"
    dst = tmp_path / "people.json"

    csv_data = ""

    src.write_text(csv_data, encoding="utf-8")

    with pytest.raises(ValueError, match="–ü—É—Å—Ç–æ–π —Ñ–∞–π–ª"):
        csv_to_json(str(src), str(dst))
    
"""–ù–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π —Ñ–∞–π–ª"""
def test_csv_to_json_empty_file(tmp_path: Path):
    src = tmp_path / "nothing.csv"
    dst = tmp_path / "people.json"

    with pytest.raises(FileNotFoundError, match="–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω"):
        csv_to_json(str(src), str(dst))

"""–ù–µ —Ç–æ—Ç —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞"""
def test_csv_to_json_type(tmp_path: Path):
    src = tmp_path / "input.txt"
    dst = tmp_path / "people.json"

    txt_data = """name,age,city,email
–ê–Ω–Ω–∞ –ò–≤–∞–Ω–æ–≤–∞,28,–ú–æ—Å–∫–≤–∞,anna@example.com
–ü–µ—Ç—Ä –°–∏–¥–æ—Ä–æ–≤,35,–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥,petr@example.com"""

    src.write_text(txt_data, encoding="utf-8")

    with pytest.raises(ValueError, match="–ù–µ–≤–µ—Ä–Ω—ã–π —Ç–∏–ø —Ñ–∞–π–ª–∞"):
        csv_to_json(str(src), str(dst))
```
![csv2json](../../images/lab07/csv_json.png)

### –ó–∞–¥–∞–Ω–∏–µ –°: black
> –í—Å–µ —Ñ–∞–π–ª—ã –ø—Ä–∏–≤–µ–¥–µ–Ω—ã –∫ —á–∏—Ç–∞–µ–º–æ–º—É –≤–∏–¥—É

![black](../../images/lab07/black.png)